{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc28ec",
   "metadata": {},
   "source": [
    "# Data Discovery - Investigando os Dados Brutos\n",
    "\n",
    "**Autor:** Felipe Freire (Diretor de operações)\n",
    "**Objetivo:** Este notebook serve como um ambiente de exploração para investigar os dados brutos, especificamente os valores únicos de colunas categóricas que precisam de limpeza e padronização.\n",
    "\n",
    "**Workflow:**\n",
    "1. Carregar o dataset **bruto** (`raw`).\n",
    "2. Para cada coluna de interesse (`estado`, `etnia`, `genero`, etc.), usar `.unique()` e `.value_counts()` para listar todas as variações existentes.\n",
    "3. Usar a saída desta análise para preencher os dicionários de mapeamento no script principal `src/analysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5afd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuração dos Caminhos ---\n",
    "# Esta célula garante que o notebook encontre os arquivos de dados corretamente\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..')) # Sobe um nível para a pasta raiz do projeto\n",
    "RAW_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw', '20250916-div_inscricoes.csv')\n",
    "\n",
    "# --- Carregando os Dados ---\n",
    "# Sempre carregamos os dados brutos aqui para garantir que estamos vendo a \"verdade\" original\n",
    "print(f\"Carregando dados de: {RAW_DATA_PATH}\")\n",
    "df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "\n",
    "print(\"\\nDados carregados com sucesso!\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1ac1a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (45909050.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip uninstall pandasql\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip uninstall pandasql\n",
    "pip uninstall sqlite3 # Tente desinstalar, mas se for um módulo nativo do Python, pode falhar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3588f7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Referenced column \"curso_titulo\" not found in FROM clause!\nCandidate bindings: \"outra_coluna\", \"turma_slug\", \"valor_coluna\"\n\nLINE 4:         curso_titulo\n                ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m conn \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 2. Executa a consulta e armazena o resultado em um novo DataFrame\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m resultado_df \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsulta_sql\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchdf()\n\u001b[0;32m     21\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m# Fecha a conexão\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultado da Consulta SQL com DuckDB:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mBinderException\u001b[0m: Binder Error: Referenced column \"curso_titulo\" not found in FROM clause!\nCandidate bindings: \"outra_coluna\", \"turma_slug\", \"valor_coluna\"\n\nLINE 4:         curso_titulo\n                ^"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "# df_raw deve estar carregado aqui...\n",
    "\n",
    "consulta_sql = \"\"\"\n",
    "    SELECT\n",
    "        turma_slug,\n",
    "        curso_titulo\n",
    "    FROM\n",
    "        df_raw  -- O DuckDB lê DataFrames como se fossem tabelas\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# 1. Conecta ao DuckDB na memória\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# 2. Executa a consulta e armazena o resultado em um novo DataFrame\n",
    "resultado_df = conn.execute(consulta_sql).fetchdf()\n",
    "\n",
    "conn.close() # Fecha a conexão\n",
    "\n",
    "print(\"\\nResultado da Consulta SQL com DuckDB:\")\n",
    "print(resultado_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c6c57",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise da Coluna `estado`\n",
    "\n",
    "Vamos inspecionar os valores da coluna de estado para identificar inconsistências (ex: \"SP\" vs \"São Paulo\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87da7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos e suas contagens para a coluna 'estado':\n",
      "['Três passos' 'Triunfo' 'São Paulo' 'Osasco' 'Cabedelo' 'Salvador'\n",
      " 'Rio de Janeiro' nan 'rio de janeiro' 'Matosinhos' 'Porto alegre'\n",
      " 'Joinville' 'Valparaiso' 'Recife' 'Santa Luzia' 'Jaú' 'Manaus'\n",
      " 'Porto Velho' 'Natal' 'Belo Horizonte' 'Malacacheta'\n",
      " 'Itapecerica da Serra' 'Sabará' 'Maceió' 'Brasília' 'Vila Velha'\n",
      " 'Angra dos Reis' 'Sumaré' 'Nova Iguaçu' 'Suzano' 'Vitória da Conquista'\n",
      " 'Guarapuava' 'Campinas' 'Florianópolis' 'João Pessoa' 'Porto Alegre'\n",
      " 'Senhor do Bonfim' 'Cachoeirinhas' 'Porto' 'Rio Branco' 'Guarulhos'\n",
      " 'Juiz de Fora' 'Blumenau' 'Betim' 'Sapiranga' 'Belém' 'Niterói'\n",
      " 'Anápolis' 'Ribeirão Preto' 'Araucária' 'Fortaleza' 'Bela Vista'\n",
      " 'São João del Rei' 'São Leopoldo' 'Rio de janeiro' 'Alfenas' 'Maua'\n",
      " 'Itaquaquecetuba' 'Presidente Prudente' 'Sertãozinho' 'Diamantina'\n",
      " 'Maracanaú' 'Vila Sônia' 'Jaguaruana' 'Canoas' 'Nova Lima'\n",
      " 'Três Corações' 'São Bernardo do Campo' 'Curitiba' 'Rio Claro'\n",
      " 'Trancoso, Porto Seguro' 'Duque de caxias' 'Ituiutaba' 'São Luís'\n",
      " 'Taubaté' 'Santa Maria' 'Águas Lindas' 'Feira de Santana' 'Paraná'\n",
      " 'Paulista' 'Mesopolis' 'Atibaia' 'Embu das Artes' 'Santo André' 'Pelotas'\n",
      " 'Maringá' 'Aracaju' 'Petrolina' 'Planaltina' 'Piracicaba'\n",
      " 'São João de Meriti' 'Brusque' 'Resende' 'Parnaíba'\n",
      " 'Caompos dos Goytacazes' 'João Monlevade' 'Nilópolis' 'Viamão'\n",
      " 'Valparaíso de Goiás' 'Jacareí' 'Araruama' 'Teresópolis' 'Olinda' 'Ijuí'\n",
      " 'Prudentópolis' 'Mamanguape' 'Votorantim' 'Mandirituba' 'Vitória'\n",
      " 'VILA VELHA' 'São Vicente' 'Capivari de Baixo' 'Uberlândia' 'São Gonçalo'\n",
      " 'Senador Canedo' 'Abreu e Lima' 'Eloi Mendes' 'Águas Lindas de Goiás'\n",
      " 'São Caetano do Sul' 'Cariacica' 'Garopaba' 'Balneário Camburiú'\n",
      " 'Goiânia' 'Florianopolis' 'São José do Vale do Rio Preto' 'Sobral'\n",
      " 'Ribeirão Pires' 'Barueri' 'Lagoa santa' 'Sorocaba' 'Ananindeua' 'Bauru'\n",
      " 'Sao Luis' 'Mamanaguape' 'Carpina' 'Barra Mansa' 'Niteroi'\n",
      " 'São Paulo, Brasil' 'Umirim' 'Pinhais' 'rio de janeiro niteroi'\n",
      " 'SÃO PAULO' 'Lisboa' 'Cuiabá' 'Rio De Janeiro' 'Ipu' 'são joão de meriti'\n",
      " 'CAMOCIM' 'São João De Meriti' 'Mongaguá' 'Crateús' 'foz do Iguaçu'\n",
      " 'itajaí' 'Goioerê' 'Bom Jesus da Lapa' 'Londrina' 'Bandeirantes'\n",
      " 'Juiz de fora' 'Ribeirão Preto/SP' 'três corações' 'Campo Grande'\n",
      " 'Ponte Nova' 'Igarassu' 'Piraquara' 'Aparecida de Goiânia' 'Uberaba'\n",
      " 'Vespasiano' 'Santos' 'Sao Paulo' 'Abaiara' 'Dourados' 'Jundiaí'\n",
      " 'Itupeva' 'Belo horizonte' 'natal' 'Caruaru' 'Campina Grande' 'são paulo'\n",
      " 'Ponta Grossa' 'Lavras' 'goiânia' 'Mauá' 'São José dos Campos'\n",
      " 'Jaboatao dos Guararapes' 'Teresina' 'niteroi' 'Guanambi' 'salvador'\n",
      " 'Nova prata do Iguaçu' 'Jales' 'São Lourenço Da Mata' 'Cosmópolis'\n",
      " 'sdfasd' 'asdf' 'São Félix de Minas' 'afsdfasdfdsa' 'Carapicuíba'\n",
      " 'Agudos' 'Paulínia' 'Santo Amaro' 'Mogi Mirim' 'Rio de Janeiro / RJ'\n",
      " 'Arujá' 'Palhoça' 'Palmas' 'Diadema' 'Praia Grande' 'Manaus - AM'\n",
      " 'Itapipoca' 'Florianópolois' 'Mairiporã' 'Gunma' 'Campos dos Goytacazes'\n",
      " 'Camaçari' 'Paracambi' 'Canindé' 'Rio das Pedras' 'Belford Roxo'\n",
      " 'São Francisco do Conde' 'Lorena' 'Limeira' 'Matão' 'Sarandi'\n",
      " 'Carapicuiba' 'Paranoá' 'Araguaina' 'Rio claro' 'Serra' 'Uberlandia' 'Bh'\n",
      " 'Guarujá' 'Sapé' 'Guarapari' 'São paulo' 'Itajubá' 'PAULISTA'\n",
      " 'São João da Boa Vista' 'Macaíba' 'Araraquara' 'Barreiro' 'SAO PAULO'\n",
      " 'BAURU' 'São Lourenço da Mata' 'SãoPaulo' 'Brasilia' 'Ilhéus'\n",
      " 'Navegantes' 'Viana' 'florianopolis' 'Imbituva' 'Rondonópolis'\n",
      " 'Campo Limpo Paulista' 'brasília' 'UBERLÂNDIA' 'Várzea Paulista'\n",
      " 'Francisco Morato' 'NATAL' 'São José do Rio Preto' 'porto alegre'\n",
      " 'São Francisco do Sul' 'Pato Branco' 'João pessoa' 'Vitória da conquista'\n",
      " 'Contagem' 'são João de meriti' 'Laranjeiras do Sul' 'Americana'\n",
      " 'Três Rios' 'Marilia' 'Ibiporã' 'Parauapebas' 'Catanduva' 'Cacequi'\n",
      " 'Santo Andre' 'Piratininga' 'Pitanga' 'Taguatinga norte'\n",
      " 'Santo Antônio de Jesus' 'Franco da rocha' 'DUQUE DE CAXIAS' 'Remígio'\n",
      " 'Parnamirim' 'São Carlos' 'Assis' 'Montes claros' 'Nova Mutum'\n",
      " 'São José dos Pinhais' 'Paranaguá' 'Brasilândia' 'Mogi das Cruzes'\n",
      " 'Camaragibe' 'belo horizonte' 'Boituva' 'Foz do Iguaçu'\n",
      " 'Santana de Parnaíba' 'Rio Grande' 'Miguel Alves' 'Curvelo'\n",
      " 'Vargem grande paulista' 'Embu das artes' 'Toledo' 'Nilopolis' 'Mirassol'\n",
      " 'Bagé' 'Duque de Caxias' 'Lages' 'Tuiuti' 'Araçatuba' 'Amadora'\n",
      " 'Mogi das cruzes' 'Boa Viagem' 'Amparo' 'Marabá' 'São José do Campestre'\n",
      " 'ARAÇATUBA' 'Irati' 'Campo grande' 'São José' 'Taboão da Serra'\n",
      " 'ANANINDEUA' 'caxias do sul' 'Cornélio Procópio' 'Delmiro Gouveia'\n",
      " 'Pato branco' 'Itápolis' 'Alvorada' 'Ibiúna' 'Boa vista' 'belém'\n",
      " 'Jaboatão dos Guararapes' 'Itararé' 'Teresopolis' 'Passos'\n",
      " 'Campos Novos Paulista' 'Cacoal' 'São Gonçalo do Amarante' 'Piedade'\n",
      " 'Crato' 'Cidade Ocidental' 'recife' 'brasilia' 'Seropédica'\n",
      " 'Capela de Santana' 'marica' 'LAURO DE FREITAS' 'Caxias do sul' 'Guaíba'\n",
      " 'LEME' 'Tenente Laurentino Cruz' 'Belford roxo'\n",
      " 'Santa Terezinha de Itaipu' 'Rj' 'Porto seguro' 'Divinópolis'\n",
      " 'Campo Mourão / PR' 'Campo mourão' 'Campos Sales' 'londrina'\n",
      " 'Porto Alegre e região' 'Várzea Grande' 'GUARULHOS' 'Brumadinho'\n",
      " 'Magé - RJ' 'recanto das emas' 'Sp' 'Canoinhas' 'jundiai' 'Biguaçu'\n",
      " 'FLORIANOPOLIS' 'Castanhal' 'Cubatão' 'Gama' 'Caucaia' 'Augusto Corrêa'\n",
      " 'Brasília - DF' 'Caieiras' 'Passo Fundo' 'Russas' 'Coração de María'\n",
      " 'São gonçalo' 'sao paulo' 'São Paulo - SP' 'florianópolis' 'Alagoinhas'\n",
      " 'são Paulo' 'Montes Claros' 'Sao paulo' 'Ipatinga' 'Fortaleza Ce'\n",
      " 'Taboão da serra' 'Itaboraí' 'Ribeirao pires' 'Santa Bárbara d’Oeste'\n",
      " 'Esteio' 'Simões Filho' 'Itatiba' 'Maricá' 'Sena Madureira' 'Franca'\n",
      " 'Porto Real' 'joão pessoa' 'Prefiro não informar' 'Jóia' 'Campo do Meio'\n",
      " 'São Paulo / SP' 'São jose do rio preto' 'Brasília De Minas' 'Matinhos'\n",
      " 'Novo Hamburgo' 'BELO HORIZONTE' 'Magé' 'guarulhos' 'diadema'\n",
      " 'Ponta Grossa - PR' 'Recife - PE' '3510609' 'PETROLINA' 'Pindamonhangaba'\n",
      " '(13) 98809-6933' 'São José de Mipibu' 'BELFORD ROXO' 'Ribeirão preto'\n",
      " 'Pontal do sul' 'Goiana' 'São Bernardo do campo' 'Juazeiro'\n",
      " \"Santa Bárbara D'Oeste\" 'Sapucaia do Sul' 'Ituverava' 'Mossoró'\n",
      " 'são leopoldo' 'Queimados' 'PIRACICABA' \"Olho d\\\\\\\\\\\\'Água do Casado\"\n",
      " 'Ramos' 'VITORIA' 'indaiatuba' 'BRASÍLIA' 'Murcia' 'Campo' 'Jucurutu'\n",
      " 'São Jose dos campos' 'Campo Bom' 'GOIÂNIA' 'LONDRINA' 'Patrocínio'\n",
      " 'Sao leopoldo' 'São José de mipibu' 'ITABORAÍ' 'PINHAIS' 'diamantina'\n",
      " 'RJ']\n"
     ]
    }
   ],
   "source": [
    "# .value_counts() é excelente pois mostra os valores e a frequência de cada um\n",
    "print(\"Valores únicos e suas contagens para a coluna 'estado':\")\n",
    "print(df_raw['cidade'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d53f91",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise da Coluna `etnia`\n",
    "\n",
    "Aqui, procuramos por variações como \"etnia_branca\", \"[branca]\", \"Branca\", além de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a52cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos e suas contagens para a coluna 'etnia':\n",
      "etnia\n",
      "etnia_branca                 657\n",
      "NaN                          413\n",
      "etnia_parda                  371\n",
      "etnia_preta                  185\n",
      "[]                           171\n",
      "[\"branca\"]                   134\n",
      "[\"parda\"]                     49\n",
      "[\"preta\"]                     37\n",
      "etnia_indigena                28\n",
      "etnia_amarela                 22\n",
      "etnia_nao_quero_responder     12\n",
      "etnia_outro                    8\n",
      "[\"amarela\"]                    6\n",
      "[\"preta\",\"parda\"]              4\n",
      "[\"indigena\"]                   1\n",
      "[\"nao_quero_responder\"]        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores únicos e suas contagens para a coluna 'etnia':\")\n",
    "print(df_raw['etnia'].value_counts(dropna=False)) # dropna=False também mostra a contagem de valores nulos (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bef416",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise da Coluna `genero`\n",
    "\n",
    "Investigamos a padronização das identidades de gênero declaradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b01f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos e suas contagens para a coluna 'genero':\n",
      "genero\n",
      "identidade_trans                           933\n",
      "NaN                                        386\n",
      "identidade_nao_binarie                     234\n",
      "[]                                         174\n",
      "[\"trans\"]                                  164\n",
      "identidade_cis                              87\n",
      "[\"nao_binarie\"]                             23\n",
      "identidade_outro                            17\n",
      "identidade_queer                            16\n",
      "identidade_nao_sei                          15\n",
      "[\"cis\"]                                      8\n",
      "identidade_nao_quero_responder               8\n",
      "[\"trans\",\"travesti\"]                         7\n",
      "[\"nao_binarie\",\"queer\"]                      5\n",
      "[\"trans\",\"nao_binarie\"]                      5\n",
      "[\"outro\",\"Transmasculino\"]                   4\n",
      "[\"travesti\"]                                 2\n",
      "[\"intersexo - 46 x,y\"]                       2\n",
      "[\"Homem\"]                                    1\n",
      "[\"transmasculino\",\"trans\"]                   1\n",
      "[\"trans\",\"nao_binarie\",\"queer\"]              1\n",
      "[\"trans\",\"nao_binarie\",\"Agênero\"]            1\n",
      "[\"queer\"]                                    1\n",
      "[\"nao_binarie\",\"queer\",\"Gênero fluido\"]      1\n",
      "[\"Transmasculino\"]                           1\n",
      "[\"nao_quero_responder\"]                      1\n",
      "[\"trans\",\"travesti\",\"queer\"]                 1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores únicos e suas contagens para a coluna 'genero':\")\n",
    "print(df_raw['genero'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c47bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analisando dados de voluntariado para a coluna 'atuacao'\n",
      "\n",
      "Valores únicos e suas contagens para a coluna 'atuacao':\n",
      "atuacao\n",
      "[\"tecnologia\"]                                                     96\n",
      "[\"comunicacao\"]                                                    23\n",
      "[\"psicologia\"]                                                     21\n",
      "[\"parcerias\"]                                                      15\n",
      "[\"engajamento\"]                                                    12\n",
      "[\"outras\"]                                                          5\n",
      "[\"comunicacao\",\"tecnologia\"]                                        4\n",
      "[\"comunicacao\", \"tecnologia\"]                                       3\n",
      "[\"tecnologia\",\"outras\"]                                             2\n",
      "[\"tecnologia\",\"comunicacao\",\"outras\"]                               2\n",
      "[\"tecnologia\",\"comunicacao\"]                                        2\n",
      "[\"engajamento\",\"comunicacao\",\"tecnologia\"]                          1\n",
      "[\"tecnologia\",\"engajamento\",\"parcerias\",\"outras\"]                   1\n",
      "[\"parcerias\",\"tecnologia\",\"comunicacao\",\"engajamento\",\"outras\"]     1\n",
      "[\"comunicacao\",\"parcerias\"]                                         1\n",
      "[\"engajamento\",\"parcerias\"]                                         1\n",
      "[\"psicologia\",\"tecnologia\"]                                         1\n",
      "[\"psicologia\", \"tecnologia\"]                                        1\n",
      "[\"comunicacao\", \"parcerias\"]                                        1\n",
      "[\"parcerias\",\"tecnologia\"]                                          1\n",
      "[\"tecnologia\", \"engajamento\"]                                       1\n",
      "[\"psicologia\", \"comunicacao\"]                                       1\n",
      "[\"tecnologia\", \"parcerias\"]                                         1\n",
      "[\"tecnologia\", \"comunicacao\"]                                       1\n",
      "[\"psicologia\",\"comunicacao\",\"engajamento\",\"outras\"]                 1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Análise da Coluna `atuacao` (Voluntariado) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Analisando dados de voluntariado para a coluna 'atuacao'\")\n",
    "\n",
    "# Carrega o dataset de voluntariado\n",
    "RAW_VOLUNTARIADO_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw', '20250916-div_voluntariado.csv')\n",
    "df_vol_raw = pd.read_csv(RAW_VOLUNTARIADO_PATH)\n",
    "\n",
    "print(\"\\nValores únicos e suas contagens para a coluna 'atuacao':\")\n",
    "print(df_vol_raw['atuacao'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a827c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Verificando dados para o cruzamento de Gênero vs. Nível Profissional\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparativo de preenchimento:\n",
      "      genero_padronizado  total_de_pessoas  com_nivel_profissional\n",
      "0              Cisgênero                96                       0\n",
      "1       Outra identidade                19                       0\n",
      "2           Pessoa Trans              1118                      69\n",
      "3  Preferiu não informar               843                     166\n",
      "4                  Queer                23                       0\n",
      "5               Travesti                 2                       1\n"
     ]
    }
   ],
   "source": [
    "# Adicione ao seu notebook para investigar\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Verificando dados para o cruzamento de Gênero vs. Nível Profissional\")\n",
    "\n",
    "# Carrega o dataset final e processado\n",
    "df_final = pd.read_csv('../data/processed/dados_consolidados_comunidade.csv')\n",
    "\n",
    "# Cria uma tabela resumo\n",
    "resumo_cruzamento = df_final.groupby('genero_padronizado').agg(\n",
    "    total_de_pessoas=('person_id', 'count'),\n",
    "    com_nivel_profissional=('professional_level_padronizado', 'count') # 'count' ignora valores nulos (NaN)\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nComparativo de preenchimento:\")\n",
    "print(resumo_cruzamento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
